name: Performance Testing

on:
  # Run on release branches and tags for full validation
  push:
    branches: [ main ]
    tags: [ 'v*' ]
  
  # Run on PRs that might affect performance
  pull_request:
    branches: [ main ]
    paths:
      - 'internal/collectors/**'
      - 'internal/differ/**'
      - 'internal/analyzer/**'
      - 'internal/storage/**'
      - 'pkg/types/**'
      - 'cmd/wgo/**'
      - 'go.mod'
      - 'go.sum'
  
  # Scheduled performance monitoring
  schedule:
    # Run nightly performance tests at 2 AM UTC
    - cron: '0 2 * * *'
  
  # Manual trigger for performance analysis
  workflow_dispatch:
    inputs:
      test_level:
        description: 'Performance test level'
        required: true
        default: 'quick'
        type: choice
        options:
        - quick
        - benchmarks
        - stress
        - comprehensive

env:
  GO_VERSION: '1.23'

jobs:
  # Quick performance validation for PRs
  performance-quick:
    name: Quick Performance Check
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Need full history for performance comparison

    - name: Set up Go
      uses: actions/setup-go@v5
      with:
        go-version: ${{ env.GO_VERSION }}
        cache: true

    - name: Run quick performance tests
      run: |
        chmod +x scripts/run-performance-tests.sh
        ./scripts/run-performance-tests.sh quick --ci
      
    - name: Upload quick performance results
      uses: actions/upload-artifact@v4
      with:
        name: performance-quick-${{ github.sha }}
        path: performance-results/
        retention-days: 7

    - name: Performance regression check
      run: |
        if [ -f performance-results/quick_bench_*.txt ]; then
          echo "## 🚀 Performance Quick Check Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          tail -20 performance-results/quick_bench_*.txt >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "✅ Quick performance validation completed" >> $GITHUB_STEP_SUMMARY
        fi

  # Comprehensive benchmarks for main branch and releases
  performance-benchmarks:
    name: Performance Benchmarks
    runs-on: ubuntu-latest
    if: |
      github.event_name == 'push' || 
      github.event_name == 'schedule' ||
      (github.event_name == 'workflow_dispatch' && github.event.inputs.test_level != 'quick')
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Go
      uses: actions/setup-go@v5
      with:
        go-version: ${{ env.GO_VERSION }}
        cache: true

    - name: Determine test level
      id: test-level
      run: |
        if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
          echo "level=${{ github.event.inputs.test_level }}" >> $GITHUB_OUTPUT
        elif [ "${{ github.event_name }}" = "schedule" ]; then
          echo "level=comprehensive" >> $GITHUB_OUTPUT
        elif [[ "${{ github.ref }}" =~ ^refs/tags/v ]]; then
          echo "level=comprehensive" >> $GITHUB_OUTPUT
        else
          echo "level=benchmarks" >> $GITHUB_OUTPUT
        fi

    - name: Run performance benchmarks
      run: |
        chmod +x scripts/run-performance-tests.sh
        ./scripts/run-performance-tests.sh ${{ steps.test-level.outputs.level }} --system-check

    - name: Upload performance results
      uses: actions/upload-artifact@v4
      with:
        name: performance-results-${{ steps.test-level.outputs.level }}-${{ github.sha }}
        path: performance-results/
        retention-days: 30

    - name: Upload profiles (if generated)
      uses: actions/upload-artifact@v4
      if: steps.test-level.outputs.level == 'comprehensive'
      with:
        name: performance-profiles-${{ github.sha }}
        path: performance-results/profiles/
        retention-days: 14

    - name: Generate performance summary
      run: |
        echo "## 📊 Performance Benchmark Results (${{ steps.test-level.outputs.level }})" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # System info
        echo "### 🖥️ Test Environment" >> $GITHUB_STEP_SUMMARY
        echo "- **OS**: $(uname -s) $(uname -r)" >> $GITHUB_STEP_SUMMARY
        echo "- **CPU Cores**: $(nproc)" >> $GITHUB_STEP_SUMMARY
        echo "- **Memory**: $(free -h | grep Mem | awk '{print $2}')" >> $GITHUB_STEP_SUMMARY
        echo "- **Go Version**: $(go version | awk '{print $3}')" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # Performance highlights
        if [ -f performance-results/performance_report_*.md ]; then
          echo "### 🚀 Performance Highlights" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Extract key metrics from benchmark results
          if ls performance-results/*benchmarks*.txt 1> /dev/null 2>&1; then
            echo "**File Processing Performance:**" >> $GITHUB_STEP_SUMMARY
            for file in performance-results/*benchmarks*.txt; do
              if grep -q "BenchmarkMegaFileProcessing" "$file"; then
                echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
                grep "BenchmarkMegaFileProcessing" "$file" | head -5 >> $GITHUB_STEP_SUMMARY
                echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
                break
              fi
            done
            echo "" >> $GITHUB_STEP_SUMMARY
          fi
          
          # Link to full report
          echo "📄 **Full Report**: Check artifacts for complete performance analysis" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
        fi
        
        # Test summary
        echo "### ✅ Test Summary" >> $GITHUB_STEP_SUMMARY
        echo "- **Test Level**: ${{ steps.test-level.outputs.level }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Trigger**: ${{ github.event_name }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Commit**: ${{ github.sha }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Results**: Available in workflow artifacts" >> $GITHUB_STEP_SUMMARY

  # Performance regression detection
  performance-regression:
    name: Performance Regression Analysis
    runs-on: ubuntu-latest
    needs: performance-benchmarks
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 50  # Get recent history for comparison

    - name: Download current results
      uses: actions/download-artifact@v4
      with:
        name: performance-results-benchmarks-${{ github.sha }}
        path: current-results/

    - name: Download baseline results
      uses: actions/download-artifact@v4
      continue-on-error: true
      with:
        name: performance-baseline
        path: baseline-results/

    - name: Analyze performance regression
      run: |
        echo "## 📈 Performance Regression Analysis" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        if [ -d baseline-results/ ] && [ -d current-results/ ]; then
          echo "Comparing current performance with baseline..." >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Simple regression detection (can be enhanced)
          echo "### 🔍 Comparison Results" >> $GITHUB_STEP_SUMMARY
          echo "- **Baseline**: Previous main branch results" >> $GITHUB_STEP_SUMMARY
          echo "- **Current**: This commit results" >> $GITHUB_STEP_SUMMARY
          echo "- **Analysis**: Manual comparison recommended" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "📊 **Action Required**: Review benchmark differences in artifacts" >> $GITHUB_STEP_SUMMARY
        else
          echo "⚠️ **No baseline found** - establishing new baseline" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "This will serve as the performance baseline for future comparisons." >> $GITHUB_STEP_SUMMARY
        fi

    - name: Update performance baseline
      uses: actions/upload-artifact@v4
      with:
        name: performance-baseline
        path: current-results/
        retention-days: 90

  # Performance monitoring alerts
  performance-monitoring:
    name: Performance Monitoring
    runs-on: ubuntu-latest
    needs: performance-benchmarks
    if: github.event_name == 'schedule'
    steps:
    - name: Download nightly results
      uses: actions/download-artifact@v4
      with:
        name: performance-results-comprehensive-${{ github.sha }}
        path: nightly-results/

    - name: Performance health check
      run: |
        echo "## 🔍 Nightly Performance Health Check" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**Date**: $(date)" >> $GITHUB_STEP_SUMMARY
        echo "**Commit**: ${{ github.sha }}" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # Check for performance issues
        if ls nightly-results/*benchmarks*.txt 1> /dev/null 2>&1; then
          echo "### 📊 Performance Metrics" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          
          # Extract key performance indicators
          for file in nightly-results/*benchmarks*.txt; do
            echo "=== $(basename "$file") ===" >> $GITHUB_STEP_SUMMARY
            grep -E "(BenchmarkMegaFileProcessing|BenchmarkConcurrentOperations)" "$file" | head -10 >> $GITHUB_STEP_SUMMARY
          done
          
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "### ✅ Status" >> $GITHUB_STEP_SUMMARY
        echo "Nightly performance monitoring completed successfully." >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "🔗 **Full Results**: Check workflow artifacts for detailed analysis" >> $GITHUB_STEP_SUMMARY

    # TODO: Add Slack/Discord notification for performance degradation
    # TODO: Add integration with performance tracking dashboard

  # Release performance validation
  release-performance:
    name: Release Performance Validation
    runs-on: ubuntu-latest
    if: startsWith(github.ref, 'refs/tags/v')
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Go
      uses: actions/setup-go@v5
      with:
        go-version: ${{ env.GO_VERSION }}
        cache: true

    - name: Run comprehensive performance validation
      run: |
        chmod +x scripts/run-performance-tests.sh
        ./scripts/run-performance-tests.sh comprehensive --system-check --profile

    - name: Upload release performance results
      uses: actions/upload-artifact@v4
      with:
        name: release-performance-${{ github.ref_name }}
        path: performance-results/
        retention-days: 365  # Keep release results for a year

    - name: Generate release performance report
      run: |
        echo "## 🚀 Release Performance Validation" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**Release**: ${{ github.ref_name }}" >> $GITHUB_STEP_SUMMARY
        echo "**Validation**: Comprehensive performance testing completed" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        if [ -f performance-results/performance_report_*.md ]; then
          echo "### 📊 Performance Certification" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "✅ **File Processing**: Large file support validated" >> $GITHUB_STEP_SUMMARY
          echo "✅ **Memory Efficiency**: Memory usage patterns validated" >> $GITHUB_STEP_SUMMARY  
          echo "✅ **Concurrent Operations**: Multi-threading performance validated" >> $GITHUB_STEP_SUMMARY
          echo "✅ **Stress Testing**: System limits and scaling validated" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "🎯 **Result**: Release performance validation **PASSED**" >> $GITHUB_STEP_SUMMARY
        fi

    # Create release performance summary
    - name: Create performance summary for release
      run: |
        if [ -f performance-results/performance_report_*.md ]; then
          cp performance-results/performance_report_*.md RELEASE_PERFORMANCE.md
          echo "" >> RELEASE_PERFORMANCE.md
          echo "---" >> RELEASE_PERFORMANCE.md
          echo "Generated for release ${{ github.ref_name }} on $(date)" >> RELEASE_PERFORMANCE.md
        fi

    - name: Upload release summary
      uses: actions/upload-artifact@v4
      with:
        name: release-performance-summary-${{ github.ref_name }}
        path: RELEASE_PERFORMANCE.md
        retention-days: 1095  # Keep for 3 years