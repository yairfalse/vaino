name: Comprehensive Tests

# Run full test suite only when needed
on:
  push:
    branches: [ main ]
    tags: [ 'v*' ]
  pull_request:
    branches: [ main ]
    types: [ opened, ready_for_review ]
  schedule:
    # Run nightly at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      test_level:
        description: 'Test level to run'
        required: true
        default: 'full'
        type: choice
        options:
        - full
        - parallel
        - performance

env:
  GO_VERSION: '1.23'

jobs:
  # Parallel test execution for maximum speed
  test-matrix:
    name: Test Matrix
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        component: [
          'terraform',
          'gcp', 
          'aws',
          'kubernetes',
          'commands',
          'config',
          'analyzer',
          'differ',
          'output',
          'storage',
          'watcher',
          'types'
        ]
        include:
          - component: 'terraform'
            path: './internal/collectors/terraform/...'
            cache_key: 'terraform'
          - component: 'gcp'
            path: './internal/collectors/gcp/...'
            cache_key: 'gcp'
          - component: 'aws'
            path: './internal/collectors/aws/...'
            cache_key: 'aws'
          - component: 'kubernetes'
            path: './internal/collectors/kubernetes/...'
            cache_key: 'kubernetes'
          - component: 'commands'
            path: './cmd/wgo/commands/...'
            cache_key: 'commands'
          - component: 'config'
            path: './pkg/config/...'
            cache_key: 'config'
          - component: 'analyzer'
            path: './internal/analyzer/...'
            cache_key: 'analyzer'
          - component: 'differ'
            path: './internal/differ/...'
            cache_key: 'differ'
          - component: 'output'
            path: './internal/output/...'
            cache_key: 'output'
          - component: 'storage'
            path: './internal/storage/...'
            cache_key: 'storage'
          - component: 'watcher'
            path: './internal/watcher/...'
            cache_key: 'watcher'
          - component: 'types'
            path: './pkg/types/...'
            cache_key: 'types'

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Go
      uses: actions/setup-go@v5
      with:
        go-version: ${{ env.GO_VERSION }}
        cache: true

    - name: Cache test results
      uses: actions/cache@v4
      with:
        path: |
          ~/.cache/go-build
          ~/go/pkg/mod
          ./${{ matrix.component }}-test-cache
        key: test-${{ matrix.cache_key }}-${{ hashFiles('go.mod', 'go.sum', matrix.path) }}
        restore-keys: |
          test-${{ matrix.cache_key }}-

    - name: Run component tests
      run: |
        echo "🧪 Testing ${{ matrix.component }} component..."
        go test -v -race -timeout 15m -coverprofile=${{ matrix.component }}-coverage.out ${{ matrix.path }}

    - name: Upload coverage
      uses: actions/upload-artifact@v4
      with:
        name: coverage-${{ matrix.component }}
        path: ${{ matrix.component }}-coverage.out
        retention-days: 1

  # Integration tests
  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: test-matrix
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Go
      uses: actions/setup-go@v5
      with:
        go-version: ${{ env.GO_VERSION }}
        cache: true

    - name: Create test fixtures
      run: |
        mkdir -p test-fixtures/terraform
        
        # Create comprehensive test state files
        cat > test-fixtures/terraform/multi-cloud.tfstate << 'EOF'
        {
          "version": 4,
          "terraform_version": "1.5.0",
          "serial": 1,
          "lineage": "test-multi-cloud",
          "resources": [
            {
              "mode": "managed",
              "type": "aws_instance",
              "name": "web",
              "provider": "provider[\"registry.terraform.io/hashicorp/aws\"]",
              "instances": [
                {
                  "schema_version": 1,
                  "attributes": {
                    "id": "i-1234567890abcdef0",
                    "instance_type": "t3.medium",
                    "ami": "ami-12345678",
                    "region": "us-west-2",
                    "tags": {
                      "Name": "web-server",
                      "Environment": "production"
                    }
                  }
                }
              ]
            },
            {
              "mode": "managed",
              "type": "google_compute_instance",
              "name": "backend",
              "provider": "provider[\"registry.terraform.io/hashicorp/google\"]",
              "instances": [
                {
                  "schema_version": 6,
                  "attributes": {
                    "id": "projects/my-project/zones/us-central1-a/instances/backend",
                    "name": "backend-server",
                    "machine_type": "e2-medium",
                    "zone": "us-central1-a"
                  }
                }
              ]
            }
          ]
        }
        EOF

    - name: Run integration tests
      run: |
        echo "🔗 Running integration tests..."
        go test -v -timeout 20m ./test/integration/...

    - name: Test CLI workflows
      run: |
        echo "💻 Testing CLI workflows..."
        make build
        
        # Test configuration workflow
        ./build/wgo configure --help
        ./build/wgo status
        ./build/wgo check-config || true  # May fail without real providers
        
        # Test scanning workflow  
        cd test-fixtures
        ../build/wgo scan --provider terraform --path . --quiet || true

  # End-to-end tests
  e2e-tests:
    name: E2E Tests
    runs-on: ubuntu-latest
    needs: test-matrix
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Go
      uses: actions/setup-go@v5
      with:
        go-version: ${{ env.GO_VERSION }}
        cache: true

    - name: Run E2E tests
      run: |
        echo "🎯 Running end-to-end tests..."
        go test -v -timeout 30m ./test/e2e/...

  # Performance tests
  performance-tests:
    name: Performance Tests
    runs-on: ubuntu-latest
    if: github.event.inputs.test_level == 'performance' || github.event_name == 'schedule'
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Go
      uses: actions/setup-go@v5
      with:
        go-version: ${{ env.GO_VERSION }}
        cache: true

    - name: Run benchmarks
      run: |
        echo "📊 Running performance benchmarks..."
        go test -bench=. -benchmem -run=^$ ./internal/collectors/terraform/...
        go test -bench=. -benchmem -run=^$ ./internal/analyzer/...
        go test -bench=. -benchmem -run=^$ ./internal/differ/...

    - name: Performance regression test
      run: |
        echo "📈 Checking for performance regressions..."
        # Run performance tests and compare with baseline
        go test -bench=. -benchmem -count=5 ./... > current_bench.txt || true
        echo "Performance results saved for analysis"

  # Coverage analysis
  coverage-analysis:
    name: Coverage Analysis
    runs-on: ubuntu-latest
    needs: test-matrix
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Download all coverage reports
      uses: actions/download-artifact@v4
      with:
        pattern: coverage-*
        merge-multiple: true

    - name: Merge coverage reports
      run: |
        echo "📊 Merging coverage reports..."
        echo "mode: atomic" > merged-coverage.out
        
        for file in *-coverage.out; do
          if [[ -f "$file" && "$file" != "merged-coverage.out" ]]; then
            tail -n +2 "$file" >> merged-coverage.out
          fi
        done

    - name: Generate coverage report
      run: |
        go tool cover -html=merged-coverage.out -o coverage.html
        go tool cover -func=merged-coverage.out > coverage-summary.txt
        
        # Extract total coverage
        TOTAL_COVERAGE=$(go tool cover -func=merged-coverage.out | grep total | awk '{print $3}')
        echo "Total coverage: $TOTAL_COVERAGE" >> $GITHUB_STEP_SUMMARY
        
        # Generate component coverage breakdown
        echo "## 📊 Coverage by Component" >> $GITHUB_STEP_SUMMARY
        echo "| Component | Coverage |" >> $GITHUB_STEP_SUMMARY
        echo "|-----------|----------|" >> $GITHUB_STEP_SUMMARY
        
        for component in terraform gcp aws kubernetes commands config analyzer differ output storage watcher types; do
          if [[ -f "${component}-coverage.out" ]]; then
            COMP_COV=$(go tool cover -func=${component}-coverage.out | grep total | awk '{print $3}' || echo "N/A")
            echo "| $component | $COMP_COV |" >> $GITHUB_STEP_SUMMARY
          fi
        done

    - name: Upload merged coverage
      uses: actions/upload-artifact@v4
      with:
        name: merged-coverage-report
        path: |
          merged-coverage.out
          coverage.html
          coverage-summary.txt

    - name: Upload to Codecov
      uses: codecov/codecov-action@v4
      with:
        file: ./merged-coverage.out
        flags: comprehensive
        name: comprehensive-coverage
        fail_ci_if_error: false

  # Build verification across platforms
  build-matrix:
    name: Build Matrix
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, macos-latest, windows-latest]
        goarch: [amd64, arm64]
        exclude:
          - os: windows-latest
            goarch: arm64

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Go
      uses: actions/setup-go@v5
      with:
        go-version: ${{ env.GO_VERSION }}
        cache: true

    - name: Build for ${{ matrix.os }}-${{ matrix.goarch }}
      run: |
        make build
        
    - name: Test binary
      run: |
        ./build/wgo --help
        ./build/wgo version

  # Security and quality
  security-scan:
    name: Security Scan
    runs-on: ubuntu-latest
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Go
      uses: actions/setup-go@v5
      with:
        go-version: ${{ env.GO_VERSION }}
        cache: true

    - name: Run gosec
      uses: securego/gosec@master
      with:
        args: -fmt sarif -out gosec-results.sarif ./...

    - name: Upload SARIF
      uses: github/codeql-action/upload-sarif@v3
      with:
        sarif_file: gosec-results.sarif

    - name: Vulnerability check
      run: |
        go install golang.org/x/vuln/cmd/govulncheck@latest
        govulncheck ./...

  # Final summary
  comprehensive-summary:
    name: Comprehensive Test Summary
    runs-on: ubuntu-latest
    needs: [
      test-matrix,
      integration-tests,
      e2e-tests,
      coverage-analysis,
      build-matrix,
      security-scan
    ]
    if: always()
    steps:
    - name: Generate comprehensive summary
      run: |
        echo "## 🎯 Comprehensive Test Results" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### Component Tests" >> $GITHUB_STEP_SUMMARY
        echo "**Matrix Tests**: ${{ needs.test-matrix.result }}" >> $GITHUB_STEP_SUMMARY
        echo "**Integration**: ${{ needs.integration-tests.result }}" >> $GITHUB_STEP_SUMMARY
        echo "**E2E Tests**: ${{ needs.e2e-tests.result }}" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### Quality & Security" >> $GITHUB_STEP_SUMMARY
        echo "**Coverage**: ${{ needs.coverage-analysis.result }}" >> $GITHUB_STEP_SUMMARY
        echo "**Security**: ${{ needs.security-scan.result }}" >> $GITHUB_STEP_SUMMARY
        echo "**Build Matrix**: ${{ needs.build-matrix.result }}" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        if [[ "${{ needs.test-matrix.result }}" == "success" && 
              "${{ needs.integration-tests.result }}" == "success" && 
              "${{ needs.build-matrix.result }}" == "success" ]]; then
          echo "✅ **Status**: All comprehensive tests passed!" >> $GITHUB_STEP_SUMMARY
        else
          echo "❌ **Status**: Some tests failed - check individual jobs" >> $GITHUB_STEP_SUMMARY
        fi

    - name: Check overall status
      if: |
        needs.test-matrix.result != 'success' ||
        needs.integration-tests.result != 'success' ||
        needs.build-matrix.result != 'success'
      run: |
        echo "❌ Comprehensive tests failed!"
        exit 1

  # Performance validation for releases
  performance-validation:
    name: Performance Validation
    runs-on: ubuntu-latest
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Go
      uses: actions/setup-go@v5
      with:
        go-version: ${{ env.GO_VERSION }}
        cache: true

    - name: Run performance benchmarks
      run: |
        echo "🚀 Running performance validation for main branch..."
        chmod +x scripts/run-performance-tests.sh
        ./scripts/run-performance-tests.sh benchmarks --system-check

    - name: Upload performance validation results
      uses: actions/upload-artifact@v4
      with:
        name: performance-validation-${{ github.sha }}
        path: performance-results/
        retention-days: 30

    - name: Performance validation summary
      run: |
        echo "## 🎯 Performance Validation Results" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**Branch**: main" >> $GITHUB_STEP_SUMMARY
        echo "**Commit**: ${{ github.sha }}" >> $GITHUB_STEP_SUMMARY
        echo "**Test Level**: benchmarks" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        if ls performance-results/*benchmarks*.txt 1> /dev/null 2>&1; then
          echo "### 📊 Key Performance Metrics" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          
          # Extract file processing performance
          for file in performance-results/*benchmarks*.txt; do
            if grep -q "BenchmarkMegaFileProcessing" "$file"; then
              echo "=== File Processing Performance ===" >> $GITHUB_STEP_SUMMARY
              grep "BenchmarkMegaFileProcessing.*-8" "$file" | head -3 >> $GITHUB_STEP_SUMMARY
              break
            fi
          done
          
          # Extract concurrent performance
          for file in performance-results/*benchmarks*.txt; do
            if grep -q "BenchmarkConcurrentOperations" "$file"; then
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "=== Concurrent Operations Performance ===" >> $GITHUB_STEP_SUMMARY
              grep "BenchmarkConcurrentOperations.*-8" "$file" | head -3 >> $GITHUB_STEP_SUMMARY
              break
            fi
          done
          
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "✅ **Status**: Performance validation completed successfully" >> $GITHUB_STEP_SUMMARY
          echo "📈 **Baseline**: Results available for future regression detection" >> $GITHUB_STEP_SUMMARY
        else
          echo "⚠️ **Warning**: No performance results found" >> $GITHUB_STEP_SUMMARY
        fi